---
name: supabase-db-migrations-cicd
description: Manages Supabase database migrations end-to-end using CLI, version control, and GitHub Actions for development and production CI/CD. Use when handling schema changes, deploying to production, configuring seeding strategies, or troubleshooting migration history mismatches.
---

# Supabase Database Migrations & CI/CD Workflow

## Quick Start

Install Supabase CLI and initialize your project:

```bash
# Install Supabase CLI (macOS/Linux)
brew install supabase/tap/supabase

# Or use npm
npm install -g supabase

# Initialize project
supabase init

# Link to remote project
supabase login
supabase link --project-ref your-project-ref
```

Create your first migration:

```bash
# Generate new migration file
supabase migration new create_users_table

# Edit supabase/migrations/<timestamp>_create_users_table.sql
# Then apply it locally
supabase db reset

# Push to production
supabase db push
```

## When to Use This Skill

- Making schema changes (create tables, add columns, create indexes)
- Deploying database changes to production via CI/CD
- Implementing environment-specific seeding (dev vs production)
- Handling zero-downtime migrations on large tables
- Troubleshooting migration history mismatches
- Setting up automated GitHub Actions workflows

## The Complete Migration Lifecycle

### 1. Local Development Workflow

**Start the local Supabase environment:**
```bash
supabase start
```

**Create a new migration file:**
```bash
supabase migration new add_users_table
```

**Write your SQL migration:**
```sql
-- supabase/migrations/20250120_add_users_table.sql
create table if not exists public.users (
  id bigint primary key generated always as identity,
  email text unique not null,
  name text,
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);

create index if not exists idx_users_email on public.users(email);
```

**Test locally:**
```bash
# Apply all pending migrations
supabase migration up

# Or reset completely (drops data, reapplies all migrations + seeds)
supabase db reset
```

**Verify migration was applied:**
```bash
supabase migration list
```

### 2. Git Workflow

Commit your migration files to version control:

```bash
git add supabase/migrations/
git add supabase/seed.sql  # if updated
git commit -m "feat: add users table with email index"
git push origin feature/users-table
```

### 3. CI/CD Deployment

**Dry-run to preview changes:**
```bash
supabase db push --dry-run
```

**Push to production (automatically runs pending migrations):**
```bash
supabase db push
```

The CLI automatically:
1. Identifies unapplied migrations
2. Creates migration history table if needed (`supabase_migrations.schema_migrations`)
3. Applies migrations in order
4. Records timestamps in migration history

## Migration File Structure & Best Practices

### File Naming Convention

```
supabase/migrations/
├── 20250120123456_create_users_table.sql
├── 20250120145032_add_department_column.sql
├── 20250121090000_create_posts_table.sql
└── 20250121094500_add_user_posts_relationship.sql
```

- Timestamp format: `YYYYMMDDhhmmss` (auto-generated by CLI)
- Name: descriptive, lowercase, underscores
- Always use `create table if not exists` and `alter table if exists` for idempotency

### Idempotency: Write Migrations That Can Run Multiple Times Safely

```sql
-- ✅ GOOD: Idempotent (safe to run multiple times)
create table if not exists public.products (
  id bigint primary key generated always as identity,
  name text unique not null
);

alter table if exists public.products
add column if not exists category text;

insert into public.products (name, category)
values ('Widget', 'Tools')
on conflict (name) do nothing;

-- ❌ BAD: Not idempotent (fails if run twice)
create table products (
  id bigint primary key generated always as identity
);

insert into public.products (name) values ('Widget');
```

### Schema Changes with ON CONFLICT for Upserts

For idempotent data operations, always use `ON CONFLICT`:

```sql
-- ✅ Safe for repeated migrations
insert into public.config (key, value)
values ('max_connections', '100')
on conflict (key) do update set value = excluded.value;
```

**Important:** `ON CONFLICT` requires a unique constraint or index:

```sql
-- First, create the unique index/constraint
alter table public.config
add constraint config_key_unique unique (key);

-- Then you can use ON CONFLICT
insert into public.config (key, value)
values ('setting_name', 'value')
on conflict (key) do update set value = excluded.value;
```

## Production CI/CD Setup: GitHub Actions

### Step 1: Create GitHub Secrets

In your GitHub repository (`Settings > Secrets and variables > Actions`), add:

```
SUPABASE_ACCESS_TOKEN    # Personal access token (from https://supabase.com/dashboard/account/tokens)
SUPABASE_PROJECT_REF     # Your project ref (e.g., abcdefghijklmnopqrst)
SUPABASE_DB_PASSWORD     # Database password (for local operations if needed)
```

### Step 2: Create GitHub Actions Workflow

**File:** `.github/workflows/deploy-migrations.yml`

```yaml
name: Deploy Database Migrations

on:
  push:
    branches:
      - main
      - staging
    paths:
      - 'supabase/migrations/**'
      - 'supabase/config.toml'

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: latest
      
      - name: Link to project
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}
        run: |
          supabase link --project-ref $SUPABASE_PROJECT_REF
      
      - name: Verify migrations (dry-run)
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          supabase db push --dry-run --linked
      
      - name: Deploy migrations to production
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          supabase db push --linked
      
      - name: Check migration status
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          supabase migration list --linked
```

### Step 3: Add Staging Environment (Optional)

For safer deployments, test on staging first:

```yaml
name: Deploy with Staging Gate

on:
  push:
    branches:
      - main

jobs:
  deploy-staging:
    runs-on: ubuntu-latest
    environment: staging
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Supabase CLI
        uses: supabase/setup-cli@v1
      
      - name: Deploy to staging
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.STAGING_SUPABASE_TOKEN }}
        run: |
          supabase link --project-ref ${{ secrets.STAGING_PROJECT_REF }}
          supabase db push --dry-run --linked
          supabase db push --linked
  
  deploy-production:
    needs: deploy-staging
    runs-on: ubuntu-latest
    environment: production
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Supabase CLI
        uses: supabase/setup-cli@v1
      
      - name: Deploy to production
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.PROD_SUPABASE_TOKEN }}
        run: |
          supabase link --project-ref ${{ secrets.PROD_PROJECT_REF }}
          supabase db push --linked
```

## Advanced: Seeding Strategies

### Split Seeding: Development vs Production

**Problem:** You want different seed data locally vs production. By default, `supabase db push --include-seed` sends seeds to production.

**Solution 1: Conditional Seed Script (Recommended)**

Create `supabase/seed.ts`:

```typescript
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.SUPABASE_URL || 'http://localhost:54321',
  process.env.SUPABASE_SERVICE_KEY || ''
);

async function seedDevelopment() {
  // Dev-only seed data
  await supabase
    .from('users')
    .insert([
      { email: 'test1@example.com', name: 'Test User 1' },
      { email: 'test2@example.com', name: 'Test User 2' },
    ]);
  
  console.log('✓ Development seeds applied');
}

async function seedProduction() {
  // Production-only seeds (minimal)
  await supabase
    .from('config')
    .insert(
      [
        { key: 'app_version', value: '1.0.0' },
        { key: 'maintenance_mode', value: 'false' }
      ],
      { onConflict: 'key' }
    );
  
  console.log('✓ Production seeds applied');
}

async function main() {
  const isProduction = process.env.ENVIRONMENT === 'production';
  
  try {
    if (isProduction) {
      await seedProduction();
    } else {
      await seedDevelopment();
    }
  } catch (error) {
    console.error('Seed error:', error);
    process.exit(1);
  }
}

main();
```

Generate SQL and run:
```bash
# Development
npx tsx supabase/seed.ts > supabase/seed.sql
supabase db reset

# Production (via GitHub Actions)
ENVIRONMENT=production npx tsx supabase/seed.ts > prod-seed.sql
```

**Solution 2: Use Snaplet for Advanced Seeding**

```bash
npm install -D @snaplet/seed

# Initialize snaplet
npx @snaplet/seed init

# Generate seed from production-like data
npx @snaplet/seed generate

# Use seed.ts to control environment-specific data
npx tsx supabase/seed.ts > supabase/seed.sql
```

### Handle Foreign Key Constraints During Seeding

```sql
-- ✅ Insert in correct order (parent tables first)

-- 1. Parent table (no dependencies)
insert into public.organizations (name)
values ('Acme Corp')
on conflict (name) do nothing;

-- 2. Child table (depends on parent)
insert into public.users (email, organization_id)
select 'user@acme.com', id
from public.organizations
where name = 'Acme Corp'
on conflict (email) do nothing;

-- 3. Grandchild table (depends on child)
insert into public.projects (user_id, title)
select id, 'Project Alpha'
from public.users
where email = 'user@acme.com'
on conflict (user_id, title) do nothing;
```

## Zero-Downtime Migrations for Large Tables

For production tables with significant data, avoid long-held locks.

### Scenario: Renaming a Column

**❌ Don't do this (causes downtime):**
```sql
alter table products rename column product_id to entity_id;
-- This locks the table for the entire operation
```

**✅ Do this instead (zero downtime):**

**Migration 1: Add new column**
```sql
alter table public.products
add column entity_id bigint;

-- Create index for performance
create index concurrently idx_products_entity_id on public.products(entity_id);
```

**Migration 2: Backfill data in batches** (run manually if very large)
```sql
-- Backfill in small batches to avoid locking
update public.products
set entity_id = product_id
where entity_id is null
limit 10000;
```

**Migration 3: Update app code to use new column** (deploy app)

**Migration 4: Drop old column** (after app is stable)
```sql
alter table public.products
drop column product_id;

-- Rename new column to final name
alter table public.products
rename column entity_id to product_id;
```

### Scenario: Adding a NOT NULL Column to Large Table

**❌ Don't do this:**
```sql
alter table large_table
add column required_field text not null default 'value';
-- Rewrites entire table
```

**✅ Do this:**

**Migration 1: Add as nullable**
```sql
alter table large_table
add column required_field text;
```

**Migration 2: Backfill values**
```sql
update large_table
set required_field = 'default_value'
where required_field is null;
```

**Migration 3: Add NOT NULL constraint**
```sql
alter table large_table
alter column required_field set not null;
```

### Using CREATE INDEX CONCURRENTLY

```sql
-- ✅ Allows reads/writes during index creation (slower but no downtime)
create index concurrently idx_users_email on public.users(email);

-- ❌ Faster but locks table
create index idx_users_email on public.users(email);
```

## Troubleshooting Common Issues

### Issue: "Migration history mismatch" error

```
Error: Local migrations don't match remote migrations
LOCAL │ REMOTE │ TIME (UTC)
──────────────┼────────────────┼──────────────────────
│ 20250120123456 │ 2025-01-20 12:34:56
20250120145032 │ │ 2025-01-20 14:50:32
```

**Solution: Repair migration history**

```bash
# Option 1: Revert the remote migration
supabase migration repair 20250120123456 --status reverted

# Option 2: Mark local migration as applied
supabase migration repair 20250120145032 --status applied

# Verify
supabase migration list --linked
```

### Issue: "Migration already applied" but local is different

```bash
# View what would be applied
supabase db push --dry-run --linked

# Fetch latest remote migrations
supabase migration fetch --linked

# If you need to force reapply a migration
supabase migration repair <timestamp> --status reverted
supabase db push --linked
```

### Issue: Lock timeout during migration

Migration takes too long, causing timeout:

**Prevention:** Add lock timeout to long-running migrations:

```sql
-- Increase timeout for this specific operation
set lock_timeout = '30 minutes';

-- Your long-running operation
alter table large_table add column new_field text;

-- Reset timeout
reset lock_timeout;
```

**Remedy:** Check running queries and cancel blocking ones:

```bash
supabase inspect db blocking --linked
supabase inspect db locks --linked
```

### Issue: Migration failed midway

**Check status:**
```bash
supabase migration list --linked
```

**Option 1: Complete the migration manually**
Connect directly and run the remainder of the migration SQL.

**Option 2: Mark migration as reverted and retry**
```bash
supabase migration repair <failed_version> --status reverted
supabase db push --linked
```

## Database Diff & Auto-Generation

Instead of writing SQL manually, generate migrations from schema changes:

```bash
# Make changes in Supabase Dashboard or directly in database

# Generate migration file
supabase db diff -f descriptive_name

# Review the generated migration
cat supabase/migrations/<timestamp>_descriptive_name.sql

# Test locally
supabase db reset

# Commit and push to version control
git add supabase/migrations/
git commit -m "chore: auto-generated migration from schema changes"
```

## Migration Squashing

When you have many small migrations, consolidate them:

```bash
# Squash all migrations up to current version
supabase migration squash --linked

# Result: All old migrations combined into one schema-only migration
# Note: Data modifications (INSERT/UPDATE) are excluded
```

**Warning:** Only squash before deploying to production. Never squash after production deployment.

## Best Practices Summary

| Do ✅ | Don't ❌ |
|---------|---------|
| Use `if not exists` and `if exists` clauses | Rely on migrations without version control |
| Write migrations with long-term compatibility | Make migrations that can't run twice |
| Test locally with `supabase db reset` | Deploy migrations without dry-run |
| Use `--dry-run` before production push | Manually edit `schema_migrations` table |
| Commit migration files to git | Rename tables/columns without two-step process |
| Create indexes `concurrently` for large tables | Lock tables with `alter table ... add column not null default` |
| Split zero-downtime migrations into multiple files | Rush through migrations in production |
| Use GitHub Actions for consistent deployment | Deploy from local machine to production |

## Key Commands Reference

```bash
# Local Development
supabase start                          # Start local Supabase
supabase stop                           # Stop local Supabase
supabase migration new <name>           # Create new migration
supabase migration up                   # Apply pending migrations
supabase db reset                       # Reset to clean state (deletes data)
supabase db diff -f <name>             # Auto-generate migration from changes

# Linking & Deployment
supabase login                          # Authenticate with Supabase account
supabase link --project-ref <ref>      # Link to remote project
supabase link                           # Link interactively

# Production Deployment
supabase db push                        # Deploy migrations to linked project
supabase db push --dry-run              # Preview what would be deployed
supabase db push --include-seed         # Deploy migrations + seed data
supabase migration list                 # Show migration status
supabase migration list --linked        # Show remote migration status

# Troubleshooting
supabase migration fetch --linked       # Fetch remote migration history
supabase migration repair <v> --status <applied|reverted>  # Fix history
supabase db pull                        # Pull remote schema as local migration
supabase inspect db blocking --linked   # View blocking queries
```

## References

- [Supabase CLI Documentation](https://supabase.com/docs/reference/cli/introduction)
- [Database Migrations Guide](https://supabase.com/docs/guides/deployment/database-migrations)
- [Managing Environments](https://supabase.com/docs/guides/deployment/managing-environments)
- [Seeding Your Database](https://supabase.com/docs/guides/local-development/seeding-your-database)
- [Zero-Downtime Postgres Migrations](https://gocardless.com/blog/zero-downtime-postgres-migrations-the-hard-parts/)
- [PostgreSQL Alter Large Tables](https://www.bytebase.com/reference/postgres/how-to/how-to-alter-large-table-postgres/)
